# =============================================================================
# AI Knowledge Assistant - Environment Variables
# =============================================================================
# Copy this file to .env.local and fill in your actual values
# DO NOT commit .env.local to version control!

# =============================================================================
# Clerk Authentication (Required)
# =============================================================================
# Get your keys from: https://clerk.com/
# Sign up and create a new application to obtain these keys
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_your_publishable_key_here
CLERK_SECRET_KEY=sk_test_your_secret_key_here

# =============================================================================
# OpenAI API (Required)
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# You need this for AI-powered document analysis and chat functionality
OPENAI_API_KEY=sk-your-openai-api-key-here

# =============================================================================
# AI Model Configuration (Optional - defaults provided)
# =============================================================================
# Main AI model for post generation
# Default: gpt-4o-mini
AI_MODEL=gpt-4o-mini

# Turbo model (currently not actively used but defined in types)
# Default: gpt-4-turbo
AI_MODEL_TURBO=gpt-4-turbo

# Mini model for chat and document processing
# Default: gpt-4o-mini
AI_MODEL_MINI=gpt-4o-mini

# Model for generating embeddings (vector search)
# Default: text-embedding-3-small
AI_MODEL_EMBEDDING=text-embedding-3-small

# Model for image generation (DALL-E)
# Default: dall-e-2
AI_MODEL_IMAGE=dall-e-2

# Image resolution for DALL-E
# Options: 256x256, 512x512, 1024x1024 (for dall-e-2)
#          1024x1024, 1792x1024, 1024x1792 (for dall-e-3)
# Default: 512x512
AI_MODEL_IMAGE_RESOLUTION=1024x1024

# =============================================================================
# Local LLM Development (Optional)
# =============================================================================
# Only used in development (NODE_ENV !== "production")
# Set this to use a local model server (e.g., Ollama, LM Studio)
# Example: http://localhost:11434
# Leave empty to use OpenAI's hosted API
MODEL_SERVER=

# Embedding model for local development
# Example: text-embedding-nomic-embed-text-v1.5
EMBEDDING_MODEL=

# =============================================================================
# News Post Generation (Optional)
# =============================================================================
# Comma-separated list of default news sources/URLs
# Default: www.google.es
DEFAULT_SOURCES=www.google.es,www.google.com

# =============================================================================
# Facebook Integration (Optional)
# =============================================================================
# Required only if you want to publish generated posts to Facebook
# Get these from: https://developers.facebook.com/
# 1. Create a Facebook App
# 2. Get a Page Access Token with 'pages_manage_posts' permission
# 3. Find your Page ID in your Facebook Page settings
FACEBOOK_API_TOKEN=your_facebook_page_access_token_here
FACEBOOK_PAGE_ID=your_facebook_page_id_here

# =============================================================================
# LangSmith Tracing (Optional - for debugging)
# =============================================================================
# Enable LangSmith tracing for debugging LangChain operations
# Get your API key from: https://smith.langchain.com/
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=your_langsmith_api_key_here
